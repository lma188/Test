Question 1
Write a function that groups observations in a data frame and returns a subset of the observations. The function must first group the observations based on one or more columns (for clarity this will be referred to as G_1). Within each G_1 it must then identify each unique combination of values based on one or more columns (this will be referred to as g_2; the columns can include any column, including those used for G_1). Finally, it must return the first n observations for every g_2.

For this question you are expected to use the provided mtcars-x.csv file.

The function must at least take the following parameters:
• the dataframe to subset (the provided mtcars-x.csv)
• which column(s) to group by (‘cyl’ in the example above)
• which column(s) to use within each group to determine the unique combinations (‘gear’ in the example above)
• the number of records to return for each unique combination (1 in the example above)

Use your function to subset the provided file to get 2 models with the lowest ‘mpg’ for each ‘gear’ and ‘carb’ combination for cars with 8 cylinders, i.e. your answer must have at most 2 records for each ‘gear’ and ‘carb’ combination.

Solution
Cleaned the data
Wrote a function to select the 2 of bottom mpg for each combination of gear and carb group by cyl.
Tested the function with an example question and checked the result.
Applied the function to answer the question and get the final answer.
Steps in details
Installed and loaded packages

# Install dplyr package
install.packages("dplyr")
  
# Load package
library(dplyr)
library(skimr)
library(knitr)
library(IRdisplay)
library(DT)

Read the file

# Read CSV file into a data frame
data <- read.csv("mtcars-x.csv",sep = ";", header = TRUE)

# Print out the data
head(data)

Summarize the data to identify any abnormal values (missing values, symbols, null values, or English numbers).
# Set the output options
options(width = 120)
options(digits = 2)

# Check variables' type
str(new_data)

Printed the rows containing abnormal values, which may include missing values or non-alphabetic numbers.
# Check for abnormal values in each row
abnormal_rows <- apply(data, 1, function(row) any(!grepl("[[:alnum:]]", row)))
                       

# Display rows with abnormal values
if (any(abnormal_rows)) {
  print("Rows with abnormal values:")
  print(data[abnormal_rows, ])
} else {
  print("No rows with abnormal values found.")
}

Dropped out missing values, converted the English numbers into integers.
Saved the new data frame with suitable variable type.
# Rename the first column as "Type"
colnames(data)[1] <- "type"

# Replace a value in a specific cell(reference from the example output)
data[24, 1] <- "Maserati Bora"

# Remove rows with majority of missing values
data <- data[complete.cases(data), ]

# convert the value of "four" with 4 and "six" with 6
data <- data %>%
  mutate(across(everything(), ~gsub("four", "4", .))) %>%
  mutate(across(everything(), ~gsub("six", "6", .)))


# Create a new data frame with the same type for each variable
new_data  <- data %>%
  mutate(
    mpg = as.numeric(mpg),
    disp = as.integer(disp),
    hp = as.integer(hp),
    drat = as.numeric(drat),
    wt = as.numeric(wt),
    qsec = as.numeric(qsec)
  )

# Print the clean data
#head(new_data)
new_data

Saved the clean data as a new file.

write.csv(new_data, file = "mtcars_output.csv", row.names = FALSE)
Writed the Function.
Define a function subset_low_values with parameters for the dataframe (df), columns to group by (group_by_cols), columns to determine unique combinations (unique_by_cols), column to arrange by (arrange_col), and the number of records to return (n).

subset_low_values <- function(df, 
                              #filter_col, 
                              #filter_value, 
                              group_by_cols, unique_by_cols, arrange_col, n) {
    
  # Filter the dataframe to include only rows where the filter_col equals the filter_value
  #df <- df %>% filter(!!sym(filter_col) == filter_value)
  
  # Group the data by the specified columns
  grouped_df <- df %>%
    group_by(across(all_of(group_by_cols)))
  
  # Sort the data within each group by the specified arrange column in ascending order
  sorted_df <- grouped_df %>%
    arrange(across(all_of(arrange_col)))
  
  # Split the sorted data into a list of dataframes, each corresponding to a group
  split_df <- sorted_df %>%
    group_split()
  
  # For each group, keep the first n rows for each unique combination of the unique_by_cols
  processed_df <- lapply(split_df, function(group) {
    group %>%
      group_by(across(all_of(unique_by_cols))) %>%
      slice_head(n = n)
  })
  
  # Combine the processed groups back into a single dataframe
  result <- bind_rows(processed_df)
  
  return(result)
}
Tested the function with example with vaild result.
# Example usage:
# group by cyl, sort by drat
# Get 1 model with the lowest drat for each gear

# Call the function
result_eg <- subset_low_values(
  df = new_data,
  #filter_col = "cyl", 
  #filter_value = 8, 
  group_by_cols = c("cyl"), 
  unique_by_cols = c("gear"), 
  arrange_col = "drat", 
  n = 1
)

# Print the example result
select(result_eg %>% arrange(cyl,gear, drat),type,drat,cyl,gear)

Applied the Function on the question to get the final answer.
# Question:
# Filter by cyl for value 8, group by cyl, sort by mpg
# Get 2 models with the lowest mpg for each combination of gear and carb


# Filter by cyl = 8
df <- new_data %>% filter(cyl == 8)
# Call the function
result <- subset_low_values(
  df = df,
  #filter_col = "cyl", 
  #filter_value = 8, 
  group_by_cols = c("cyl"), 
  unique_by_cols = c("gear", "carb"), 
  arrange_col = "mpg", 
  n = 2
)

# Print the final result
select(result,type, mpg ,gear,carb,cyl)

Question 2
Load the provided Lorem Ipsum text and answer the following questions.

# Load the text file
text <- readLines("lorem-ipsum.txt")
a) How many paragraphs are in the text?
Assumption
Split the text into paragraphs based on line breaks.

Solution
# Function to count the number of paragraphs in the text
count_paragraphs <- function(text) {
    
# Split the text into paragraphs based on line breaks
  paragraphs <- strsplit(paste(text, collapse = "\n"), "\n\n")[[1]]
    
# Count the number of paragraphs
  num_paragraphs <- length(paragraphs)  
    
  return(num_paragraphs)
}

# Call the Function
num_paragraphs <- count_paragraphs(text)

# Print the result
print(paste("Number of paragraphs:", num_paragraphs))

b) How many sentences is it comprised of?
Assumption
Split the text into sentences using regular expression based on a period, exclamation mark, or question mark followed by one or more whitespace characters.

Solution
# Function to count the number of sentences in the text
count_sentences <- function(text) {
    
  # Combine paragraphs into a single string
  combined_text <- paste(text, collapse = " ")
  
  # Split the text into sentences using regular expression
  # Based on a period, exclamation mark, or question mark followed by one or more whitespace characters.
  sentences <- unlist(strsplit(combined_text, "[.!?]\\s+"))
  
  # Count the number of sentences
  num_sentences <- length(sentences)
  
  return(num_sentences)
}

# Call the Function
num_sentences <- count_sentences(text)

# Print the result
print(paste("Number of sentences:", num_sentences))

c) Which paragraph has the most sentences?
Assumptions
Split the text into paragraphs based on line breaks.
Split the paragraph into sentences using regular expression based on a period, exclamation mark, or question mark followed by one or more whitespace characters.
Solution
Calculated the number of sentences in paragraph.
Identified the paragraph with the most sentences.
# Function to count the number of sentences in a given paragraph
count_sentences_in_paragraph <- function(paragraph) {
    
  # Split the paragraph into sentences using regular expression
  # Based on a period, exclamation mark, or question mark followed by one or more whitespace characters.
  sentences <- unlist(strsplit(paragraph, "[.!?]\\s+"))
    
  return(length(sentences))
}

# Function to identify and print the paragraph with the most sentences
paragraph_with_most_sentences <- function(text) {
    
  # Split the text into paragraphs based on line breaks
  paragraphs <- strsplit(paste(text, collapse = "\n"), "\n\n")[[1]]
  
  # Count the number of sentences in each paragraph
  sentence_counts <- sapply(paragraphs, count_sentences_in_paragraph)
  
  # Find the index of the paragraph with the most sentences
  max_index <- which.max(sentence_counts)
  
  return(paragraphs[max_index])
  
}

# Call the function 
paragraphs<- paragraph_with_most_sentences(text)

# Print the result
print(paste("Paragraph with the most sentences:", paragraphs))

d) How many words are in the text?
Assumption
Split the text into words using whitespace as the delimiter.

Solution
# Function to count the number of words in the text
count_words <- function(text) {
    
  # Combine all lines into a single string
  combined_text <- paste(text, collapse = " ")
  
  # Split the text into words using whitespace as the delimiter.
  words <- unlist(strsplit(combined_text, "\\s+"))
  
  # Count the number of words
  num_words <- length(words)
  
  return(num_words)
}

# Call the function
num_words <- count_words(text)

# Print the result
print(paste("Number of words:", num_words))

e) Which are the 5 most and least common words, with how many occurrences?
Assumptions
Number is not counted as a word.
If the frequency is the same, order by alphabetical order.
Solution
Combine all lines into a single string, convert to lowercase, remove punctuation and numbers.
Split the text into words using whitespace as the delimiter.
Calculate the occurrences of each word.
Sort the table by frequency in decreasing order; if frequency is the same, order alphabetically.
Get the top 5 most common words and bottom 5 least common words (excluding empty strings).
Print results in data frame.
# Function to find the 5 most and least common words in the text
find_common_words <- function(text) {
  
  # Combine all lines into a single string
  combined_text <- paste(text, collapse = " ")
  
  # Convert to lowercase to ensure case insensitivity
  combined_text <- tolower(combined_text)
  
  # Remove punctuation
  combined_text <- gsub("[[:punct:]]", "", combined_text)
  
  # Remove numbers
  combined_text <- gsub("\\d", "", combined_text)
  
  # Split the text into words using whitespace as the delimiter
  words <- unlist(strsplit(combined_text, "\\s+"))
  
  # Remove empty strings
  words <- words[words != ""]
  
  # Calculate the occurrences of each word
  word_counts <- table(words)
    
  # Sort the table by frequency in decreasing order
  # If the frequency is the same, order by alphabetical order
  sorted_word_counts <- sort(word_counts, decreasing = TRUE, index.return = TRUE)
  
  # Get the top 5 most common words
  most_common <- head(sorted_word_counts, 5)
  
  # Get the bottom 5 least common words (excluding empty string if any)
  least_common <- tail(sorted_word_counts[sorted_word_counts > 0], 5)
  
  # Convert to data frames for better readability
  most_common_df <- data.frame(
    Word = names(most_common),
    Frequency = as.integer(most_common)
  )
  
  least_common_df <- data.frame(
    Word = names(least_common),
    Frequency = as.integer(least_common)
  )
  
  # Print the results
  cat("Top 5 most common words with their occurrences:\n")
  print(most_common_df)
  
  cat("\nBottom 5 least common words with their occurrences:\n")
  print(least_common_df)
}

# Print the result
find_common_words(text)

f) Which are the longest words in the text?
Assumption
Number is not counted as a word.

Solution
Combine all lines into a single string, convert to lowercase, remove punctuation and numbers.
Split the text into words using whitespace as the delimiter.
Calculate the length of each word.
Find the word with the maximum length.
Print result in data frame.
# Function to find the longest words in the text
find_longest_words <- function(text) {
  # Combine all lines into a single string
  combined_text <- paste(text, collapse = " ")
  
  # Convert to lowercase to ensure case insensitivity
  combined_text <- tolower(combined_text)
  
  # Remove punctuation
  combined_text <- gsub("[[:punct:]]", "", combined_text)
  
  # Remove numbers
  combined_text <- gsub("\\d+", "", combined_text)
  
  # Split the text into words using whitespace as the delimiter
  words <- unlist(strsplit(combined_text, "\\s+"))
  
  # Remove empty strings
  words <- words[words != ""]
  
  # Calculate the length of each word
  word_lengths <- nchar(words)
  
  # Find the index of the longest word
  longest_word_index <- which.max(word_lengths)
  
  # Get the longest word and its length
  longest_word <- words[longest_word_index]
  longest_word_length <- word_lengths[longest_word_index]
  
  # Create a data frame for the longest word
  longest_word_df <- data.frame(
    Word = longest_word,
    Length = longest_word_length
  )
  
  # Print the result
  cat("Longest word in the text and its length:\n")
  print(longest_word_df)
}

# Print the result
find_longest_words(text)

Question 3
Write efficient R code to evaluate the following when n = 250.
$$\sum_{i=1}^{n} (2i-1)^{3} - \left(\sum_{i=1}^{n} (2i-1)\right)^{3}$$

Solution
# Define the function to evaluate the formula
calculate_expression <- function(n) {

# Generate the sequence of terms (2i-1) up to n
  terms <- 2*(1:n) - 1
  
# Calculate the sum of the terms
  sum_of_terms <- sum(terms)
  
# Calculate the sum of the cubed terms
  sum_of_cubed_terms <- sum(terms^3)
  
# Compute the final result by subtracting the cube of the sum of terms from the sum of cubed terms
  result <- sum_of_cubed_terms - sum_of_terms^3
  
# Return the result
  return(result)
}

# Example usage with n = 250
n <- 250

# Call the function
result <- calculate_expression(n)

# Set options to display full number without scientific notation
options(scipen = 999)

# Print result without scientific notation
print(result)
